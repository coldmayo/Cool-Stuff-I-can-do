{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me trying to learn deep learning with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset to be used\n",
    "#The dataset is basically a bunch of handwritten numbers\n",
    "mnist = tf.keras.datasets.mnist\n",
    "#x-train and x-test are appart of the training set and y-test and y-train are appart of the test set\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 157us/sample - loss: 0.2961 - accuracy: 0.9140\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1419 - accuracy: 0.9577\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1093 - accuracy: 0.9658\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0884 - accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.0754 - accuracy: 0.9765\n",
      "10000/1 - 1s - loss: 0.0407 - accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08049258911972866, 0.9749]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One epoch is the time step that is incremented every time it has went through all the samples in the training set.\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "#Computer's prediction\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is me trying to figure out how predictive models work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengthinfeet</th>\n",
       "      <th>weightintons</th>\n",
       "      <th>speedmph</th>\n",
       "      <th>biteforcenewtons</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>182000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3340</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>42.6</td>\n",
       "      <td>9.75</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>156001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lengthinfeet  weightintons  speedmph  biteforcenewtons  Species\n",
       "0          40.0          7.00      18.0             57000        0\n",
       "1          21.0         60.00      20.0            182000        1\n",
       "2          43.0          8.60      31.0              3340        2\n",
       "3          42.6          9.75      17.0             56900        0\n",
       "4          44.0         50.00      19.0            156001        1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#use one-word names for columns or it will give you an error\n",
    "CSV_COLUMN_NAMES = ['lengthinfeet', 'weightintons', 'speedmph', 'biteforcenewtons', 'Species']\n",
    "SPECIES = ['T-rex', 'Megalodon', 'Giganotosaurus']\n",
    "#Make sure the \n",
    "train = pd.read_csv('Dino_train.csv', names=CSV_COLUMN_NAMES, skipinitialspace=True, skiprows=1, engine=\"python\")\n",
    "test = pd.read_csv('Dino_test.csv', names=CSV_COLUMN_NAMES, skipinitialspace=True, skiprows=1, engine=\"python\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\WALLAC~1\\AppData\\Local\\Temp\\tmpla3umzp6\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\WALLAC~1\\\\AppData\\\\Local\\\\Temp\\\\tmpla3umzp6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000017F48513908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "def input_evaluation_set():\n",
    "    features = {'lengthinfeet': np.array([40.0, 21.0]),\n",
    "                'weightintons':  np.array([7.00, 60.00]),\n",
    "                'speedmph': np.array([18.0, 20.0]),\n",
    "                'biteforcenewtons':  np.array([57000, 182000])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels\n",
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\WALLAC~1\\AppData\\Local\\Temp\\tmpla3umzp6\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2334.2407, step = 0\n",
      "INFO:tensorflow:global_step/sec: 266.421\n",
      "INFO:tensorflow:loss = 119.55055, step = 100 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.853\n",
      "INFO:tensorflow:loss = 83.301956, step = 200 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.236\n",
      "INFO:tensorflow:loss = 47.304398, step = 300 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.857\n",
      "INFO:tensorflow:loss = 30.088928, step = 400 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.477\n",
      "INFO:tensorflow:loss = 18.484423, step = 500 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.015\n",
      "INFO:tensorflow:loss = 3.94039, step = 600 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.294\n",
      "INFO:tensorflow:loss = 7.091568, step = 700 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.797\n",
      "INFO:tensorflow:loss = 6.180553, step = 800 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.145\n",
      "INFO:tensorflow:loss = 5.40903, step = 900 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.964\n",
      "INFO:tensorflow:loss = 4.4910774, step = 1000 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.959\n",
      "INFO:tensorflow:loss = 4.0780706, step = 1100 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.808\n",
      "INFO:tensorflow:loss = 3.2708473, step = 1200 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.987\n",
      "INFO:tensorflow:loss = 2.9100137, step = 1300 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.737\n",
      "INFO:tensorflow:loss = 2.4565659, step = 1400 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.582\n",
      "INFO:tensorflow:loss = 2.1550052, step = 1500 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.905\n",
      "INFO:tensorflow:loss = 2.2243779, step = 1600 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.201\n",
      "INFO:tensorflow:loss = 2.0645156, step = 1700 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.308\n",
      "INFO:tensorflow:loss = 1.9469223, step = 1800 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.378\n",
      "INFO:tensorflow:loss = 1.6955731, step = 1900 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.709\n",
      "INFO:tensorflow:loss = 5.5895467, step = 2000 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.319\n",
      "INFO:tensorflow:loss = 1.082522, step = 2100 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.878\n",
      "INFO:tensorflow:loss = 2.1246004, step = 2200 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.936\n",
      "INFO:tensorflow:loss = 1.403252, step = 2300 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.804\n",
      "INFO:tensorflow:loss = 0.28355128, step = 2400 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.855\n",
      "INFO:tensorflow:loss = 0.4879588, step = 2500 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.414\n",
      "INFO:tensorflow:loss = 0.1535883, step = 2600 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.19\n",
      "INFO:tensorflow:loss = 0.72358084, step = 2700 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.458\n",
      "INFO:tensorflow:loss = 0.08537151, step = 2800 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.691\n",
      "INFO:tensorflow:loss = 0.87706447, step = 2900 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.602\n",
      "INFO:tensorflow:loss = 0.68332803, step = 3000 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.608\n",
      "INFO:tensorflow:loss = 1.8499402, step = 3100 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.778\n",
      "INFO:tensorflow:loss = 0.19267803, step = 3200 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.294\n",
      "INFO:tensorflow:loss = 0.49563682, step = 3300 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.586\n",
      "INFO:tensorflow:loss = 0.56827456, step = 3400 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.667\n",
      "INFO:tensorflow:loss = 0.13437168, step = 3500 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.198\n",
      "INFO:tensorflow:loss = 0.11194341, step = 3600 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.355\n",
      "INFO:tensorflow:loss = 0.2857955, step = 3700 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.961\n",
      "INFO:tensorflow:loss = 0.060770817, step = 3800 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.833\n",
      "INFO:tensorflow:loss = 0.25666606, step = 3900 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.988\n",
      "INFO:tensorflow:loss = 0.32972473, step = 4000 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.651\n",
      "INFO:tensorflow:loss = 0.22677308, step = 4100 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.374\n",
      "INFO:tensorflow:loss = 0.067193136, step = 4200 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.312\n",
      "INFO:tensorflow:loss = 0.1965732, step = 4300 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.496\n",
      "INFO:tensorflow:loss = 0.05557674, step = 4400 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.389\n",
      "INFO:tensorflow:loss = 0.06159585, step = 4500 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.828\n",
      "INFO:tensorflow:loss = 0.073426165, step = 4600 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.933\n",
      "INFO:tensorflow:loss = 0.120600656, step = 4700 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.699\n",
      "INFO:tensorflow:loss = 0.08197924, step = 4800 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.318\n",
      "INFO:tensorflow:loss = 0.10996074, step = 4900 (0.215 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\WALLAC~1\\AppData\\Local\\Temp\\tmpla3umzp6\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.28509602.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-02T15:10:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WALLAC~1\\AppData\\Local\\Temp\\tmpla3umzp6\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-02-15:10:21\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 1.0, average_loss = 0.095848106, global_step = 5000, loss = 0.095848106\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\WALLAC~1\\AppData\\Local\\Temp\\tmpla3umzp6\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)\n",
    "\n",
    "eval_result = classifier.evaluate(\n",
    "input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WALLAC~1\\AppData\\Local\\Temp\\tmpla3umzp6\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"T-rex\" (95.9%), expected \"T-rex\"\n",
      "Prediction is \"Megalodon\" (99.3%), expected \"Megalodon\"\n",
      "Prediction is \"Giganotosaurus\" (99.9%), expected \"Giganotosaurus\"\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['T-rex', 'Megalodon', 'Giganotosaurus']\n",
    "predict_x = {\n",
    "    'lengthinfeet': [41.5, 23, 44],\n",
    "    'weightintons': [7.1, 59.3, 8.4],\n",
    "    'speedmph': [18.6, 20.6, 30],\n",
    "    'biteforcenewtons': [57023, 182023, 3342],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
